{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220314_deepfm_avazudata_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HTDrrkN4kpIf9CxEH9LdJBzrm5Tnaoug",
      "authorship_tag": "ABX9TyOyb3fMpYjJkzrDE6uXcZhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeohuiPark/MLDLstudy/blob/main/deepfm_avazudata_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 link code: \n",
        "\n",
        "https://deepctr-torch.readthedocs.io/en/latest/Examples.html\n",
        "\n",
        "https://www.kaggle.com/sagu123/ctr-analysis-ipynb\n",
        "\n",
        "https://github.com/shenweichen/DeepCTR-Torch\n",
        "\n"
      ],
      "metadata": {
        "id": "S2hDz2sh63sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 전체 데이터 40,428,967 - 40만 - colab에서 불러오기 안됨\n",
        "* 10만개만 샘플링한 후 load"
      ],
      "metadata": {
        "id": "oCy1OWL4ld-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "chazgTvACiTB",
        "outputId": "ecabe842-3967-421e-9c8d-4a5e551dfc38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install deepctr-torch"
      ],
      "metadata": {
        "id": "5LGowNrh5LbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024d9293-ea51-4ea7-b02b-dc209d247e4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepctr-torch\n",
            "  Downloading deepctr_torch-0.2.7-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 70 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from deepctr-torch) (1.10.0+cu111)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from deepctr-torch) (0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from deepctr-torch) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepctr-torch) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->deepctr-torch) (3.10.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->deepctr-torch) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr-torch) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr-torch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr-torch) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr-torch) (1.21.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.13.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.0.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr-torch) (1.44.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->deepctr-torch) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->deepctr-torch) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, deepctr-torch\n",
            "Successfully installed deepctr-torch-0.2.7 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "import torch\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models import *"
      ],
      "metadata": {
        "id": "lbIMwrn4_C19"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_load():\n",
        "    print(\"\\n\\n1. data load \")\n",
        "    data_path = \"/content/drive/MyDrive/Colab Notebooks/2022_recom_study/ctr_sample_dataset/abazu_dataset/\"\n",
        "    data = pd.read_csv(data_path + \"avazu_sample_10.csv\")\n",
        "    display(data.head(3))\n",
        "    print(data.columns)\n",
        "    print(data.shape) \n",
        "    return data"
      ],
      "metadata": {
        "id": "kqezTuOMpzqR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(data):\n",
        "    print(\"\\n\\n2. feature selection \")\n",
        "\n",
        "    sparse_features = data.columns.tolist()\n",
        "    sparse_features.remove('click')\n",
        "    sparse_features.remove('hour')\n",
        "    dense_features = ['hour']\n",
        "\n",
        "    print(\"sparse feature :\", sparse_features)\n",
        "    print(\"dense feature :\", dense_features)\n",
        "    print(\"target :\", 'click')\n",
        "\n",
        "    return data, sparse_features, dense_features"
      ],
      "metadata": {
        "id": "oSxWn7O9dSZX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_encoding(data, sparse_features, dense_features):\n",
        "\n",
        "    print(\"\\n\\n3-1. feature encoding \")\n",
        "    print(\"categorical value to numeric label\")\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    print(\"numeric value Minmax scaling \")\n",
        "    mms = MinMaxScaler(feature_range=(0, 1)) ### date 더 최근일 수록 더 큰 숫자가 입력됨 \n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "EIxiSgid8pcJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_format_deepfm(data, sparse_features, dense_features, embedding_dim):\n",
        "\n",
        "    print(f\"\\n\\n3-2. feature embedding - embedding size {embedding_dim}\")\n",
        "    spar_feat_list = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1, embedding_dim=embedding_dim) for i, feat in enumerate(sparse_features)]\n",
        "    dense_feat_list = [DenseFeat(feat, 1, ) for feat in dense_features]\n",
        "    fixlen_feature_columns = spar_feat_list + dense_feat_list\n",
        "\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    return dnn_feature_columns, linear_feature_columns, feature_names"
      ],
      "metadata": {
        "id": "sW_nxwtXpzyk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(data, test_rato, feature_names, random_seed):\n",
        "    print(f\"\\n\\n4. data split (test ratio - {test_rato})\")\n",
        "    train, test = train_test_split(data, test_size=test_rato, random_state = random_seed)\n",
        "    train_model_input = {name: train[name] for name in feature_names}\n",
        "    test_model_input = {name: test[name] for name in feature_names}\n",
        "\n",
        "    return train, test, train_model_input, test_model_input "
      ],
      "metadata": {
        "id": "UXRNEfuu9PYa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modeling(linear_feature_columns, dnn_feature_columns,\n",
        "             batch_size, num_epoch, val_ratio, test_rato, l2_decay_val, random_seed):\n",
        "    \n",
        "    print(f\"\\n\\n5. Modeling\")\n",
        "    model = DeepFM(linear_feature_columns=linear_feature_columns,  \n",
        "               dnn_feature_columns=dnn_feature_columns, \n",
        "               l2_reg_linear=l2_decay_val, l2_reg_embedding=l2_decay_val, l2_reg_dnn=l2_decay_val,\n",
        "               dnn_dropout=0.5, \n",
        "               dnn_use_bn = True,\n",
        "               dnn_hidden_units=(32, 16),\n",
        "               task='binary',\n",
        "               seed=random_seed, device=device)\n",
        "\n",
        "\n",
        "    model.compile(\"adam\", \"binary_crossentropy\", \n",
        "                metrics=[\"binary_crossentropy\", \"auc\"], )\n",
        "\n",
        "\n",
        "    return model \n"
      ],
      "metadata": {
        "id": "XhsAhTqs9BMg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test(model, test_model_input, batch_size ):\n",
        "    print(f\"\\n\\n6. Evaluation testset\")\n",
        "    pred_ans = model.predict(test_model_input, batch_size) #batch_size default : 256\n",
        "    print(\"\")\n",
        "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "metadata": {
        "id": "5IqM9yuS9atA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. modeling"
      ],
      "metadata": {
        "id": "u1i6G_O4oQt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    batch_size = 1000\n",
        "    num_epoch = 20\n",
        "    val_ratio = 0.1\n",
        "    test_rato = 0.1\n",
        "    random_seed = 2022\n",
        "    l2_decay_val = 1e-01\n",
        "    embedding_dim = 5\n",
        "\n",
        "    device = 'cpu'\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('cuda ready...')\n",
        "        device = 'cuda:0'\n",
        "\n",
        "\n",
        "    data = data_load()\n",
        "    target = ['click']\n",
        "\n",
        "    data, sparse_features, dense_features = feature_selection(data)\n",
        "    data = feature_encoding(data, sparse_features, dense_features)\n",
        "\n",
        "    dnn_feature_columns, linear_feature_columns, feature_names = feature_format_deepfm(data, sparse_features, dense_features, embedding_dim)\n",
        "\n",
        "    train, test, train_model_input, test_model_input = data_split(data, test_rato, \n",
        "                                                                  feature_names, random_seed)\n",
        "\n",
        "    model = modeling(linear_feature_columns, dnn_feature_columns,\n",
        "             batch_size, num_epoch, val_ratio, test_rato, l2_decay_val, random_seed)\n",
        "    \n",
        "    model.fit(train_model_input, train[target].values,\n",
        "            batch_size=batch_size, epochs=num_epoch, verbose=2, validation_split=val_ratio)\n",
        "    \n",
        "    eval_test(model, test_model_input, batch_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TZpLTqexKFM3",
        "outputId": "1a7cbb4c-845e-4be0-cf1a-8b0ee8f0b72e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda ready...\n",
            "\n",
            "\n",
            "1. data load \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
              "0  3.572791e+18      0  14102518  1005           1  856e6d3f    58a89a43   \n",
              "1  3.299518e+18      0  14102404  1005           0  d9750ee7    98572c79   \n",
              "2  3.990806e+18      0  14102907  1005           0  517b8671    ac5abf20   \n",
              "\n",
              "  site_category    app_id app_domain  ... device_type device_conn_type    C14  \\\n",
              "0      f028772b  ecad2386   7801e8d9  ...           1                0  18854   \n",
              "1      f028772b  ecad2386   7801e8d9  ...           1                0  21153   \n",
              "2      f028772b  ecad2386   7801e8d9  ...           1                0  23642   \n",
              "\n",
              "   C15  C16   C17  C18  C19  C20  C21  \n",
              "0  320   50  1882    3   35   -1   13  \n",
              "1  320   50  2420    2   35   -1   69  \n",
              "2  320   50  2709    3   35   -1   23  \n",
              "\n",
              "[3 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4348794-4b11-46df-b35f-0df017a0333c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>click</th>\n",
              "      <th>hour</th>\n",
              "      <th>C1</th>\n",
              "      <th>banner_pos</th>\n",
              "      <th>site_id</th>\n",
              "      <th>site_domain</th>\n",
              "      <th>site_category</th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_domain</th>\n",
              "      <th>...</th>\n",
              "      <th>device_type</th>\n",
              "      <th>device_conn_type</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.572791e+18</td>\n",
              "      <td>0</td>\n",
              "      <td>14102518</td>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>856e6d3f</td>\n",
              "      <td>58a89a43</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18854</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1882</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.299518e+18</td>\n",
              "      <td>0</td>\n",
              "      <td>14102404</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>d9750ee7</td>\n",
              "      <td>98572c79</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21153</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2420</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.990806e+18</td>\n",
              "      <td>0</td>\n",
              "      <td>14102907</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>517b8671</td>\n",
              "      <td>ac5abf20</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23642</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2709</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4348794-4b11-46df-b35f-0df017a0333c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4348794-4b11-46df-b35f-0df017a0333c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4348794-4b11-46df-b35f-0df017a0333c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
            "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
            "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
            "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21'],\n",
            "      dtype='object')\n",
            "(100000, 24)\n",
            "\n",
            "\n",
            "2. feature selection \n",
            "sparse feature : ['id', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
            "dense feature : ['hour']\n",
            "target : click\n",
            "\n",
            "\n",
            "3-1. feature encoding \n",
            "categorical value to numeric label\n",
            "numeric value Minmax scaling \n",
            "\n",
            "\n",
            "3-2. feature embedding - embedding size 5\n",
            "\n",
            "\n",
            "4. data split (test ratio - 0.1)\n",
            "\n",
            "\n",
            "5. Modeling\n",
            "cuda:0\n",
            "Train on 81000 samples, validate on 9000 samples, 81 steps per epoch\n",
            "Epoch 1/20\n",
            "2s - loss:  0.4807 - binary_crossentropy:  0.4794 - auc:  0.6223 - val_binary_crossentropy:  0.4279 - val_auc:  0.7085\n",
            "Epoch 2/20\n",
            "1s - loss:  0.3631 - binary_crossentropy:  0.3571 - auc:  0.8065 - val_binary_crossentropy:  0.4116 - val_auc:  0.7217\n",
            "Epoch 3/20\n",
            "1s - loss:  0.0236 - binary_crossentropy:  0.0132 - auc:  0.9998 - val_binary_crossentropy:  0.4475 - val_auc:  0.6926\n",
            "Epoch 4/20\n",
            "1s - loss:  0.0089 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.5140 - val_auc:  0.6884\n",
            "Epoch 5/20\n",
            "1s - loss:  0.0073 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.5706 - val_auc:  0.6925\n",
            "Epoch 6/20\n",
            "1s - loss:  0.0061 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.6374 - val_auc:  0.6975\n",
            "Epoch 7/20\n",
            "1s - loss:  0.0053 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.6759 - val_auc:  0.7030\n",
            "Epoch 8/20\n",
            "1s - loss:  0.0046 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.7233 - val_auc:  0.7074\n",
            "Epoch 9/20\n",
            "1s - loss:  0.0041 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.7508 - val_auc:  0.7108\n",
            "Epoch 10/20\n",
            "1s - loss:  0.0037 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.8009 - val_auc:  0.7130\n",
            "Epoch 11/20\n",
            "1s - loss:  0.0033 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.8225 - val_auc:  0.7144\n",
            "Epoch 12/20\n",
            "1s - loss:  0.0030 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.8467 - val_auc:  0.7156\n",
            "Epoch 13/20\n",
            "1s - loss:  0.0028 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.9039 - val_auc:  0.7164\n",
            "Epoch 14/20\n",
            "1s - loss:  0.0025 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.8825 - val_auc:  0.7172\n",
            "Epoch 15/20\n",
            "1s - loss:  0.0024 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.9666 - val_auc:  0.7174\n",
            "Epoch 16/20\n",
            "1s - loss:  0.0022 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.9581 - val_auc:  0.7175\n",
            "Epoch 17/20\n",
            "1s - loss:  0.0020 - binary_crossentropy:  0.0000 - auc:  1.0000 - val_binary_crossentropy:  0.9483 - val_auc:  0.7178\n",
            "Epoch 18/20\n",
            "1s - loss:  0.0019 - binary_crossentropy:  0.0001 - auc:  1.0000 - val_binary_crossentropy:  0.9558 - val_auc:  0.7180\n",
            "Epoch 19/20\n",
            "1s - loss:  0.0018 - binary_crossentropy:  0.0000 - auc:  1.0000 - val_binary_crossentropy:  1.0066 - val_auc:  0.7183\n",
            "Epoch 20/20\n",
            "1s - loss:  0.0017 - binary_crossentropy:  0.0000 - auc:  1.0000 - val_binary_crossentropy:  1.0427 - val_auc:  0.7182\n",
            "\n",
            "\n",
            "6. Evaluation testset\n",
            "\n",
            "test LogLoss 1.0367\n",
            "test AUC 0.7225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reverse Engineering - for studying"
      ],
      "metadata": {
        "id": "hTcXBpwdFgnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FM(nn.Module):\n",
        "    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n",
        "     without linear term and bias.\n",
        "      Input shape\n",
        "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
        "      Output shape\n",
        "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
        "      References\n",
        "        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FM, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        fm_input = inputs\n",
        "\n",
        "        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n",
        "        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True) \n",
        "        cross_term = square_of_sum - sum_of_square \n",
        "        cross_term = 0.5 * torch.sum(cross_term, dim=2, keepdim=False)\n",
        "\n",
        "        return cross_term\n"
      ],
      "metadata": {
        "id": "45vy_zmRVsbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from deepctr_torch.models.basemodel import BaseModel\n",
        "from deepctr_torch.inputs import combined_dnn_input\n",
        "from deepctr_torch.layers import FM, DNN\n",
        "\n",
        "class DeepFM(BaseModel):\n",
        "    \"\"\"Instantiates the DeepFM Network architecture.\n",
        "    :param linear_feature_columns: An iterable containing all the features used by linear part of the model. (-> FM에 들어갈 피쳐, 전체 피쳐)\n",
        "    \n",
        "    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model. (-> DNN에 들어갈 피쳐, 전체 피쳐)  \n",
        "    :param use_fm: bool,use FM part or not (FM 사용할지 말지)\n",
        "    \n",
        "    :param dnn_hidden_units: list,list of positive integer or empty list, \n",
        "       the layer number and units in each layer of DNN (-> DNN 모델 layer 개수 - default 256, 128)\n",
        "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.(->딥러닝 dropout)\n",
        "    :param dnn_activation: Activation function to use in DNN (-> 딥러닝 활성함수) \n",
        "    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN (->딥러닝 배치norm)\n",
        "    \n",
        "\n",
        "    :param l2_reg_linear: float. L2 regularizer strength applied to linear part (-> FM l2 정규화 정도, defalut 1e-5) \n",
        "    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector (-> embedding l2 정규화 정도, defalut 1e-5) \n",
        "    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN (-> dnn l2 정규화 정도, defalut 1e-5) \n",
        "    \n",
        "    :param init_std: float,to use as the initialize std of embedding vector (-> 임베딩 초기 표준편차)\n",
        "    :param seed: integer ,to use as random seed. (-> 랜덤시드)\n",
        "\n",
        "    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss (->태스크 - 이진분류 / 회귀)\n",
        "    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"`` (->cpu, gpu 선택)\n",
        "    :param gpus: list of int or torch.device for multiple gpus. If None, run on `device`. `gpus[0]` should be the same gpu with `device`.\n",
        "    :return: A PyTorch model instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 linear_feature_columns, dnn_feature_columns, use_fm=True,\n",
        "                 dnn_hidden_units=(256, 128),\n",
        "                 l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, init_std=0.0001, seed=1024,\n",
        "                 dnn_dropout=0,\n",
        "                 dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu', gpus=None):\n",
        "\n",
        "        super(DeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n",
        "                                     l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n",
        "                                     device=device, gpus=gpus)\n",
        "\n",
        "        self.use_fm = use_fm\n",
        "        self.use_dnn = len(dnn_feature_columns) > 0 and len(\n",
        "            dnn_hidden_units) > 0\n",
        "        \n",
        "        if use_fm: ### FM model 로딩\n",
        "            self.fm = FM()\n",
        "\n",
        "        if self.use_dnn: ### dnn part 에서 쓰일 모델들 선언 \n",
        "            self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
        "                           activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
        "                           init_std=init_std, device=device)\n",
        "            self.dnn_linear = nn.Linear(\n",
        "                dnn_hidden_units[-1], 1, bias=False).to(device)\n",
        "\n",
        "            self.add_regularization_weight(\n",
        "                filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2=l2_reg_dnn)\n",
        "            self.add_regularization_weight(self.dnn_linear.weight, l2=l2_reg_dnn)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, X): ### 학습 \n",
        "\n",
        "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n",
        "                                                                                  self.embedding_dict)\n",
        "        ## 1) FM 연산 \n",
        "        ### 1.1) 선형 모델 통과 \n",
        "        logit = self.linear_model(X) ## 결과값 추가 \n",
        "        \n",
        "        ### 1.2) fm 연산 (칼럼끼리 곱)\n",
        "        if self.use_fm and len(sparse_embedding_list) > 0: \n",
        "            fm_input = torch.cat(sparse_embedding_list, dim=1)\n",
        "            logit += self.fm(fm_input) ## 결과값 추가 \n",
        "\n",
        "        ## 2) DNN 학습 \n",
        "        if self.use_dnn: \n",
        "            dnn_input = combined_dnn_input(\n",
        "                sparse_embedding_list, dense_value_list) \n",
        "            dnn_output = self.dnn(dnn_input)\n",
        "            dnn_logit = self.dnn_linear(dnn_output)\n",
        "            logit += dnn_logit ## 결과값 추가 \n",
        "\n",
        "        y_pred = self.out(logit)\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "ktdqRp30Cwvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}