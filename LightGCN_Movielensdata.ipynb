{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeohuiPark/MLDLstudy/blob/main/LightGCN_Movielensdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GGkjSb48t5yX",
        "outputId": "6059a626-301c-4f2d-ab82-9555c2e0a4e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 9.7 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpCsjOOJuvU0",
        "outputId": "fa4b9d44-423e-4366-f871-83e451077a4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "metadata": {
        "id": "l3eWDnnHwMrp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load"
      ],
      "metadata": {
        "id": "GUkkfOLvu3fm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nRM39FZFt5yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be9f260-c812-4af8-c076-6bff8ca08f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load user and movie nodes\n",
        "def load_node_csv(path, index_col):\n",
        "    \"\"\"Loads csv containing node information\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        index_col (str): column name of index column\n",
        "\n",
        "    Returns:\n",
        "        dict: mapping of csv row to node id\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, index_col=index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "    return mapping\n",
        "\n",
        "\n",
        "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
        "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
      ],
      "metadata": {
        "id": "dms14ekUu5Yy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        src_index_col (str): column name of users\n",
        "        src_mapping (dict): mapping between row number and user id\n",
        "        dst_index_col (str): column name of items\n",
        "        dst_mapping (dict): mapping between row number and item id\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    edge_index = None\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "\n",
        "    return torch.tensor(edge_index)\n",
        "\n",
        "\n",
        "edge_index = load_edge_csv(\n",
        "    rating_path,\n",
        "    src_index_col='userId',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='movieId',\n",
        "    dst_mapping=movie_mapping,\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=4,\n",
        ")"
      ],
      "metadata": {
        "id": "3EYACm5Eu7Wc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "metadata": {
        "id": "JG97tHFJu9G2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))"
      ],
      "metadata": {
        "id": "kI-762oPu_vZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "metadata": {
        "id": "XYkiHvkRvLvx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Light gcn 적용"
      ],
      "metadata": {
        "id": "KRvTsRmFvOVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "metadata": {
        "id": "YlqGJg1QvQI5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "VvinTcwAvRm3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "metadata": {
        "id": "8ys0GytSvVzi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "metadata": {
        "id": "Kz1Y-xHivXIM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "metadata": {
        "id": "UM1UAwK9vY02"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "metadata": {
        "id": "GUbFaUX-vZ8h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "metadata": {
        "id": "C0tzPOSZvbKj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZlkGqvzvcSu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training"
      ],
      "metadata": {
        "id": "vuFTPWLHvdhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20\n",
        "LAMBDA = 1e-6"
      ],
      "metadata": {
        "id": "g_ykNOWXveS9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVxF7gcKvekW",
        "outputId": "47edc08a-9e97-4642-f1ef-f1b8d27eb880"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLtoyiADvgnd",
        "outputId": "3837ad73-c246-4e5f-ea34-8f7a2a2c8668"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/10000] train_loss: -0.69127, val_loss: -0.68383, val_recall@20: 0.00285, val_precision@20: 0.00108, val_ndcg@20: 0.00184\n",
            "[Iteration 200/10000] train_loss: -0.69973, val_loss: -0.68982, val_recall@20: 0.04511, val_precision@20: 0.01555, val_ndcg@20: 0.03457\n",
            "[Iteration 400/10000] train_loss: -0.88528, val_loss: -0.82529, val_recall@20: 0.14482, val_precision@20: 0.04195, val_ndcg@20: 0.1039\n",
            "[Iteration 600/10000] train_loss: -1.75456, val_loss: -1.5355, val_recall@20: 0.14635, val_precision@20: 0.04458, val_ndcg@20: 0.10636\n",
            "[Iteration 800/10000] train_loss: -3.42045, val_loss: -2.88356, val_recall@20: 0.15279, val_precision@20: 0.04611, val_ndcg@20: 0.10914\n",
            "[Iteration 1000/10000] train_loss: -5.65386, val_loss: -4.55293, val_recall@20: 0.15492, val_precision@20: 0.04602, val_ndcg@20: 0.10886\n",
            "[Iteration 1200/10000] train_loss: -7.29566, val_loss: -6.35086, val_recall@20: 0.15143, val_precision@20: 0.04602, val_ndcg@20: 0.1076\n",
            "[Iteration 1400/10000] train_loss: -9.92386, val_loss: -8.25941, val_recall@20: 0.14931, val_precision@20: 0.04593, val_ndcg@20: 0.10666\n",
            "[Iteration 1600/10000] train_loss: -12.47466, val_loss: -10.2487, val_recall@20: 0.15103, val_precision@20: 0.0462, val_ndcg@20: 0.10714\n",
            "[Iteration 1800/10000] train_loss: -14.69907, val_loss: -12.10922, val_recall@20: 0.15146, val_precision@20: 0.04593, val_ndcg@20: 0.10683\n",
            "[Iteration 2000/10000] train_loss: -18.116, val_loss: -14.11533, val_recall@20: 0.15141, val_precision@20: 0.04602, val_ndcg@20: 0.10614\n",
            "[Iteration 2200/10000] train_loss: -19.92274, val_loss: -16.16745, val_recall@20: 0.15386, val_precision@20: 0.04611, val_ndcg@20: 0.10706\n",
            "[Iteration 2400/10000] train_loss: -22.58837, val_loss: -18.21691, val_recall@20: 0.15123, val_precision@20: 0.04593, val_ndcg@20: 0.10637\n",
            "[Iteration 2600/10000] train_loss: -24.29689, val_loss: -20.05757, val_recall@20: 0.14971, val_precision@20: 0.04602, val_ndcg@20: 0.10638\n",
            "[Iteration 2800/10000] train_loss: -26.50756, val_loss: -22.13884, val_recall@20: 0.15048, val_precision@20: 0.04602, val_ndcg@20: 0.10659\n",
            "[Iteration 3000/10000] train_loss: -30.25316, val_loss: -23.69023, val_recall@20: 0.15035, val_precision@20: 0.04593, val_ndcg@20: 0.10606\n",
            "[Iteration 3200/10000] train_loss: -30.38363, val_loss: -25.45152, val_recall@20: 0.15046, val_precision@20: 0.04611, val_ndcg@20: 0.10626\n",
            "[Iteration 3400/10000] train_loss: -32.91787, val_loss: -27.03709, val_recall@20: 0.1502, val_precision@20: 0.04575, val_ndcg@20: 0.10613\n",
            "[Iteration 3600/10000] train_loss: -35.09729, val_loss: -29.29329, val_recall@20: 0.15057, val_precision@20: 0.04602, val_ndcg@20: 0.10627\n",
            "[Iteration 3800/10000] train_loss: -37.35183, val_loss: -30.6701, val_recall@20: 0.15036, val_precision@20: 0.04584, val_ndcg@20: 0.10647\n",
            "[Iteration 4000/10000] train_loss: -39.26561, val_loss: -32.17318, val_recall@20: 0.15073, val_precision@20: 0.0462, val_ndcg@20: 0.10649\n",
            "[Iteration 4200/10000] train_loss: -39.65368, val_loss: -33.23853, val_recall@20: 0.15084, val_precision@20: 0.04602, val_ndcg@20: 0.1065\n",
            "[Iteration 4400/10000] train_loss: -42.34329, val_loss: -35.12378, val_recall@20: 0.1513, val_precision@20: 0.04629, val_ndcg@20: 0.1067\n",
            "[Iteration 4600/10000] train_loss: -43.9415, val_loss: -36.37756, val_recall@20: 0.15106, val_precision@20: 0.04638, val_ndcg@20: 0.10669\n",
            "[Iteration 4800/10000] train_loss: -47.02432, val_loss: -37.89373, val_recall@20: 0.15077, val_precision@20: 0.04611, val_ndcg@20: 0.10648\n",
            "[Iteration 5000/10000] train_loss: -46.81413, val_loss: -39.25178, val_recall@20: 0.15096, val_precision@20: 0.04629, val_ndcg@20: 0.10662\n",
            "[Iteration 5200/10000] train_loss: -48.86297, val_loss: -40.16928, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10705\n",
            "[Iteration 5400/10000] train_loss: -50.1557, val_loss: -41.50732, val_recall@20: 0.14975, val_precision@20: 0.04629, val_ndcg@20: 0.10625\n",
            "[Iteration 5600/10000] train_loss: -50.90266, val_loss: -42.42144, val_recall@20: 0.15111, val_precision@20: 0.04638, val_ndcg@20: 0.10651\n",
            "[Iteration 5800/10000] train_loss: -54.6349, val_loss: -43.84409, val_recall@20: 0.15096, val_precision@20: 0.04638, val_ndcg@20: 0.10658\n",
            "[Iteration 6000/10000] train_loss: -52.98495, val_loss: -45.11901, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10676\n",
            "[Iteration 6200/10000] train_loss: -59.67696, val_loss: -45.59261, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10677\n",
            "[Iteration 6400/10000] train_loss: -58.3962, val_loss: -45.99972, val_recall@20: 0.15021, val_precision@20: 0.04647, val_ndcg@20: 0.10639\n",
            "[Iteration 6600/10000] train_loss: -56.18933, val_loss: -46.76974, val_recall@20: 0.15021, val_precision@20: 0.04647, val_ndcg@20: 0.10638\n",
            "[Iteration 6800/10000] train_loss: -59.95308, val_loss: -47.93102, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.1066\n",
            "[Iteration 7000/10000] train_loss: -58.57687, val_loss: -49.30414, val_recall@20: 0.15202, val_precision@20: 0.04656, val_ndcg@20: 0.10679\n",
            "[Iteration 7200/10000] train_loss: -60.79037, val_loss: -50.11324, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10662\n",
            "[Iteration 7400/10000] train_loss: -64.3515, val_loss: -50.59228, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10662\n",
            "[Iteration 7600/10000] train_loss: -62.8099, val_loss: -51.53535, val_recall@20: 0.15156, val_precision@20: 0.04647, val_ndcg@20: 0.10666\n",
            "[Iteration 7800/10000] train_loss: -63.46418, val_loss: -52.12068, val_recall@20: 0.15216, val_precision@20: 0.04656, val_ndcg@20: 0.10688\n",
            "[Iteration 8000/10000] train_loss: -64.29879, val_loss: -53.0456, val_recall@20: 0.15156, val_precision@20: 0.04647, val_ndcg@20: 0.10668\n",
            "[Iteration 8200/10000] train_loss: -65.93056, val_loss: -53.62684, val_recall@20: 0.15216, val_precision@20: 0.04656, val_ndcg@20: 0.10689\n",
            "[Iteration 8400/10000] train_loss: -66.67037, val_loss: -54.03228, val_recall@20: 0.15161, val_precision@20: 0.04656, val_ndcg@20: 0.10673\n",
            "[Iteration 8600/10000] train_loss: -67.28384, val_loss: -54.35284, val_recall@20: 0.15161, val_precision@20: 0.04656, val_ndcg@20: 0.10672\n",
            "[Iteration 8800/10000] train_loss: -67.25391, val_loss: -55.18803, val_recall@20: 0.15136, val_precision@20: 0.04638, val_ndcg@20: 0.10655\n",
            "[Iteration 9000/10000] train_loss: -66.8959, val_loss: -55.33427, val_recall@20: 0.15136, val_precision@20: 0.04638, val_ndcg@20: 0.10655\n",
            "[Iteration 9200/10000] train_loss: -70.74689, val_loss: -56.46812, val_recall@20: 0.15156, val_precision@20: 0.04647, val_ndcg@20: 0.10665\n",
            "[Iteration 9400/10000] train_loss: -68.6204, val_loss: -56.38788, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.1066\n",
            "[Iteration 9600/10000] train_loss: -69.74596, val_loss: -57.19276, val_recall@20: 0.15141, val_precision@20: 0.04647, val_ndcg@20: 0.10661\n",
            "[Iteration 9800/10000] train_loss: -70.2056, val_loss: -57.16173, val_recall@20: 0.15224, val_precision@20: 0.04665, val_ndcg@20: 0.1069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lEYYjeWXvh5L",
        "outputId": "9fc36646-52fb-4fe6-9a7e-9b19bf0588c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XcVWX2Gvjwg",
        "outputId": "d060a161-d184-407b-a20d-351f64af5853"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -52.13276, test_recall@20: 0.12521, test_precision@20: 0.0471, test_ndcg@20: 0.10179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inference -- 유저에게 영화 추천 "
      ],
      "metadata": {
        "id": "D-yr0Igavm94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "metadata": {
        "id": "gsaFJZ_yvp5D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "qZfs7zIsvqL-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y639zPgSvr-d",
        "outputId": "1798c6a1-5876-4298-d153-dcd507e87c95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: Star Wars: Episode VI - Return of the Jedi (1983), genres: Action|Adventure|Sci-Fi \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Lion King, The (1994), genres: Adventure|Animation|Children|Drama|Musical|IMAX \n",
            "title: Memento (2000), genres: Mystery|Thriller \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KxZuS5tyE-P"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}